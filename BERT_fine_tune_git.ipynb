{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Fine-tune\n"
      ],
      "metadata": {
        "id": "_Wf5vaTrNdAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Prep\n"
      ],
      "metadata": {
        "id": "Jzlcvpt9k7IM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ov-qvV-i6hQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "csv_file = 'url'\n",
        "df = pd.read_csv(csv_file, delimiter=',')\n",
        "df = df[df['altlabel_it'].str.lower() != 'none']\n",
        "\n",
        "neg_file = 'url'\n",
        "neg_df = pd.read_csv(neg_file, delimiter=',')\n",
        "neg_df = neg_df[neg_df['altlabel_es'].str.lower() != 'none']\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_df[['pref_label', 'altlabel_it']].rename(columns={'pref_label': 'source', 'altlabel_it': 'target'}).to_dict(orient='records')\n",
        "test_data = test_df[['pref_label', 'altlabel_it']].rename(columns={'pref_label': 'source', 'altlabel_it': 'target'}).to_dict(orient='records')\n",
        "\n",
        "#list to JSON format\n",
        "json_data = json.dumps(train_data, indent=4, ensure_ascii=False)\n",
        "with open('train_data.json', 'w', encoding='utf-8') as json_file:\n",
        "    json_file.write(json_data)"
      ],
      "metadata": {
        "id": "xjI6v3egloBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get a negative example from a different language\n",
        "def get_negatives_diff_lang(neg_df, positive_example):\n",
        "    negative_text = random.choice(\n",
        "        [alt.split(', ')[0] for alt in neg_df['altlabel_es'] if alt.split(', ')[0] != positive_example]\n",
        "    )\n",
        "    return negative_text"
      ],
      "metadata": {
        "id": "Dh1bGt0JN27P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Setup"
      ],
      "metadata": {
        "id": "Ga0aIth4l81B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFAutoModel\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = TFAutoModel.from_pretrained('bert-base-multilingual-cased') #TFautomodel / automodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0AiP3j0Ck1I",
        "outputId": "003c4e3d-41c3-4f71-8981-ab2b4be63dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df = test_df\n",
        "test_df_sampled = test_df.sample(n=5, random_state=42) #perplexity must be less than n.\n",
        "\n",
        "# Extract labels from the sampled DataFrame\n",
        "source_labels = test_df_sampled['pref_label'].tolist()\n",
        "target_labels = test_df_sampled['altlabel_it'].tolist()\n",
        "\n",
        "source_inputs = tokenizer(source_labels, return_tensors='tf', padding=True, truncation=True)\n",
        "target_inputs = tokenizer(target_labels, return_tensors='tf', padding=True, truncation=True)\n",
        "\n",
        "# Generate embeddings for labels\n",
        "source_outputs = model(source_inputs)\n",
        "source_embeddings = source_outputs.last_hidden_state[:, 0, :].numpy()  # Use the [CLS] token's embeddings\n",
        "target_outputs = model(target_inputs)\n",
        "target_embeddings = target_outputs.last_hidden_state[:, 0, :].numpy()  # Use the [CLS] token's embeddings"
      ],
      "metadata": {
        "id": "qz7AALtTAml_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23d5812-2e35-4f7b-d3aa-4b819063fdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine embeddings for t-SNE\n",
        "all_embeddings = np.concatenate((source_embeddings, target_embeddings), axis=0)\n",
        "\n",
        "# Dimensionality reduction using t-SNE\n",
        "n_samples = len(source_labels) + len(target_labels)\n",
        "perplexity = min(2, n_samples - 1)  # Ensure perplexity is less than the number of samples\n",
        "tsne = TSNE(n_components=2, random_state=0, perplexity=perplexity)\n",
        "embeddings_2d = tsne.fit_transform(all_embeddings)\n"
      ],
      "metadata": {
        "id": "R6Y5AYsHC3pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize embeddings"
      ],
      "metadata": {
        "id": "BRBMrjtHFUoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import kaleido\n",
        "\n",
        "def visualize_embeddings_plotly(embeddings, source_labels, target_labels, title):\n",
        "    \"\"\"\n",
        "    Visualizes embeddings using t-SNE with Plotly, connecting source-target pairs with lines.\n",
        "    \"\"\"\n",
        "\n",
        "      # Perform t-SNE to reduce dimensionality to 2D\n",
        "    tsne = TSNE(n_components=2, random_state=0, perplexity=2)\n",
        "    embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "\n",
        "    #Limit to 5 labels for both source and target\n",
        "    source_labels = source_labels[:10]\n",
        "    target_labels = target_labels[:10]\n",
        "    embeddings = embeddings[:20]  # 5 sources + 5 targets\n",
        "\n",
        "    # Perform t-SNE to reduce dimensionality to 2D\n",
        "    # tsne = TSNE(n_components=2, random_state=42, perplexity=2, n_iter=500, learning_rate=200)\n",
        "    # embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # Separate source and target embeddings in the 2D space\n",
        "    num_sources = len(source_labels)\n",
        "    source_embeddings_2d = embeddings_2d[:num_sources]\n",
        "    target_embeddings_2d = embeddings_2d[num_sources:]\n",
        "\n",
        "    # Create a figure for Plotly\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Plot each source-target pair\n",
        "    for i in range(num_sources):\n",
        "        # Add a line connecting source and target\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[source_embeddings_2d[i, 0], target_embeddings_2d[i, 0]],\n",
        "            y=[source_embeddings_2d[i, 1], target_embeddings_2d[i, 1]],\n",
        "            mode='lines',\n",
        "            line=dict(color='gray', width=1),\n",
        "            showlegend=False\n",
        "        ))\n",
        "\n",
        "        # Add source point (circle shape)\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[source_embeddings_2d[i, 0]],\n",
        "            y=[source_embeddings_2d[i, 1]],\n",
        "            mode='markers+text',\n",
        "            marker=dict(symbol='circle', color='blue', size=15),\n",
        "            name='Source',\n",
        "            text=[source_labels[i]],\n",
        "            textposition='top right',  # Adjusting position\n",
        "            textfont=dict(size=14, color='blue', family='Arial'),\n",
        "            showlegend=(i == 0),\n",
        "        ))\n",
        "\n",
        "        # Add target point (square shape)\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[target_embeddings_2d[i, 0]],\n",
        "            y=[target_embeddings_2d[i, 1]],\n",
        "            mode='markers+text',\n",
        "            marker=dict(symbol='square', color='red', size=15),\n",
        "            name='Target',\n",
        "            text=[target_labels[i]],\n",
        "            textposition='bottom left',  # Adjusting position\n",
        "            textfont=dict(size=14, color='red', family='Arial'),\n",
        "            showlegend=(i == 0),\n",
        "        ))\n",
        "\n",
        "    # Customize layout with additional margin and larger figure size\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis_title='Dimension 1 (t-SNE)',\n",
        "        yaxis_title='Dimension 2 (t-SNE)',\n",
        "        legend_title_text='Label Type',\n",
        "        xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n",
        "        yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
        "        margin=dict(l=40, r=40, t=40, b=40),  # Add margins to avoid text cutoffs\n",
        "        width=1200,  # Increase figure width\n",
        "        height=400  # Increase figure height\n",
        "    )\n",
        "\n",
        "    # Show the figure\n",
        "    fig.show()\n",
        "\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "EXCod10NqygI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training"
      ],
      "metadata": {
        "id": "nn7WeZY1r0Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Ensure eager execution (only necessary if using TensorFlow 1.x)\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Extract initial embeddings\n",
        "source_outputs = model(source_inputs)\n",
        "source_embeddings = source_outputs.last_hidden_state[:, 0, :].numpy()\n",
        "target_outputs = model(target_inputs)\n",
        "target_embeddings = target_outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "# Combine embeddings for visualization\n",
        "initial_embeddings = np.concatenate((source_embeddings, target_embeddings), axis=0)\n",
        "\n",
        "# Visualize initial embeddings with Plotly\n",
        "fig = visualize_embeddings_plotly(initial_embeddings, source_labels, target_labels, 'Initial BERT Embeddings')\n",
        "\n",
        "\n",
        "# Save the figure as a PDF\n",
        "#save_and_download_plot(fig, \"/content/altlabel_it_before.pdf\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "DysqM5r1zVGo",
        "outputId": "87a29fed-32d9-472f-ffd9-0d6d2bd7b77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1563b99b-974f-4d2c-8c48-a3e04d946863\" class=\"plotly-graph-div\" style=\"height:400px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1563b99b-974f-4d2c-8c48-a3e04d946863\")) {                    Plotly.newPlot(                        \"1563b99b-974f-4d2c-8c48-a3e04d946863\",                        [{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[-3.6949286460876465,10.25949478149414],\"y\":[107.19287872314453,31.805017471313477],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":true,\"text\":[\"Hafnium tetrachloride\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[-3.6949286460876465],\"y\":[107.19287872314453],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":true,\"text\":[\"Cloruro di afnio(IV)\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[10.25949478149414],\"y\":[31.805017471313477],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[-71.32227325439453,-63.32963943481445],\"y\":[-47.73653793334961,-55.32133865356445],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Wittichenite\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[-71.32227325439453],\"y\":[-47.73653793334961],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"Wittichenite\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[-63.32963943481445],\"y\":[-55.32133865356445],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[3.38785982131958,1.9174877405166626],\"y\":[98.432861328125,20.08304214477539],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Barium chlorate\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[3.38785982131958],\"y\":[98.432861328125],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"Clorato di bario, clorato di bario bario clorato\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[1.9174877405166626],\"y\":[20.08304214477539],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[-80.00408172607422,14.090225219726562],\"y\":[-64.88093566894531,15.645936965942383],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Quartz\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[-80.00408172607422],\"y\":[-64.88093566894531],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"Biossido di silice, Diossido di silicio, quarzo, silanamina, 1,1,1-trimetil-N-\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[14.090225219726562],\"y\":[15.645936965942383],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[15.446721076965332,23.619112014770508],\"y\":[85.61508178710938,70.15383911132812],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Cyanuric acid\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[15.446721076965332],\"y\":[85.61508178710938],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"acido cianurico\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[23.619112014770508],\"y\":[70.15383911132812],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Label Type\"}},\"xaxis\":{\"title\":{\"text\":\"Dimension 1 (t-SNE)\"},\"scaleanchor\":\"y\",\"scaleratio\":1},\"yaxis\":{\"title\":{\"text\":\"Dimension 2 (t-SNE)\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"margin\":{\"l\":40,\"r\":40,\"t\":40,\"b\":40},\"title\":{\"text\":\"Initial BERT Embeddings\"},\"width\":1200,\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1563b99b-974f-4d2c-8c48-a3e04d946863');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show kaleido\n",
        "import kaleido\n",
        "import plotly.graph_objects as go\n",
        "from google.colab import files\n",
        "\n",
        "# Function to save figure as PDF and download it\n",
        "def save_and_download_plot_as_pdf(fig, file_name):\n",
        "    # Save the figure as PDF\n",
        "    img_bytes = fig.to_image(format=\"pdf\")\n",
        "\n",
        "    # Write the image to a file\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(img_bytes)\n",
        "\n",
        "    # Download the file\n",
        "    files.download(file_name)\n",
        "\n",
        "# Example usage\n",
        "save_and_download_plot_as_pdf(fig, '/content/altlabel_it_before.pdf')"
      ],
      "metadata": {
        "id": "QJjlajhU4CK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-tuning\n",
        "dataset is not created.\n",
        "refer: https://huggingface.co/docs/transformers/en/model_doc/bert"
      ],
      "metadata": {
        "id": "WPyAvAHoVWub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom training and Test loop demo"
      ],
      "metadata": {
        "id": "1QKnInbYRt59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved Testing Loop\n",
        "def test_model(test_df, threshold=1.0):\n",
        "    def calculate_distance(embedding1, embedding2):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(embedding1 - embedding2), axis=-1))\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_distance = 0\n",
        "    distances = []\n",
        "\n",
        "    for _, row in test_df.iterrows():\n",
        "        source_text = row['pref_label']\n",
        "        target_text = row['altlabel_it']\n",
        "\n",
        "        # Tokenize inputs\n",
        "        source_input = tokenize(source_text)\n",
        "        target_input = tokenize(target_text)\n",
        "\n",
        "        # Compute embeddings\n",
        "        source_output = bert_model_demo(source_input['input_ids'], attention_mask=source_input['attention_mask']).last_hidden_state[:, 0, :]\n",
        "        target_output = bert_model_demo(target_input['input_ids'], attention_mask=target_input['attention_mask']).last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Calculate distance\n",
        "        distance = calculate_distance(source_output, target_output).numpy()\n",
        "        total_distance += distance\n",
        "        distances.append(distance)\n",
        "\n",
        "        if distance < threshold:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct_predictions / len(test_df)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "zDR1k6j4GjEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFAutoModel\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer_demo = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "bert_model_demo = TFAutoModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Define the triplet loss function\n",
        "def triplet_loss(anchor, positive, negative, margin=5.0):\n",
        "    # TODO: (1) test sqrt done , (2) increase margin - done wrote a tiny function to check later incase needed.\n",
        "    # TODO: (1) increase num of training examples - done (2) get positive and negative from other languages (not only german)\n",
        "    pos_dist = tf.sqrt(tf.reduce_sum(tf.square(anchor - positive), axis=-1))\n",
        "    neg_dist = tf.sqrt(tf.reduce_sum(tf.square(anchor - negative), axis=-1))\n",
        "    loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "# Tokenize the inputs\n",
        "def tokenize(text):\n",
        "    return tokenizer_demo(text, return_tensors='tf', padding=True, truncation=True)\n",
        "\n",
        "#The warning is due to a future change in the transformers library, where clean_up_tokenization_spaces will default to False.\n",
        "\n",
        "# Experiment with different margins\n",
        "def experiment_with_margins(anchor_output, positive_output, negative_output):\n",
        "    for margin in [0.1, 0.5, 1.0, 2.0, 5.0]:\n",
        "        loss = triplet_loss(anchor_output, positive_output, negative_output, margin=margin)\n",
        "        print(f\"Margin: {margin}, Loss: {loss.numpy()}\")\n",
        "\n",
        "# Training Loop\n",
        "def train_model(data, epochs=5, learning_rate=2e-5):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    #optimizer = Adam(learning_rate=learning_rate)\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        with tqdm(total=len(data), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
        "          for anchor_text, positive_text, negative_text in data:\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Tokenize inputs\n",
        "                anchor_input = tokenize(anchor_text)\n",
        "                positive_input = tokenize(positive_text)\n",
        "                negative_input = tokenize(negative_text)\n",
        "\n",
        "                # Compute embeddings\n",
        "                anchor_output = bert_model_demo(anchor_input['input_ids'], attention_mask=anchor_input['attention_mask']).last_hidden_state[:, 0, :]\n",
        "                positive_output = bert_model_demo(positive_input['input_ids'], attention_mask=positive_input['attention_mask']).last_hidden_state[:, 0, :]\n",
        "                negative_output = bert_model_demo(negative_input['input_ids'], attention_mask=negative_input['attention_mask']).last_hidden_state[:, 0, :]\n",
        "\n",
        "                # Calculate the triplet loss\n",
        "                loss = triplet_loss(anchor_output, positive_output, negative_output)\n",
        "                total_loss += loss\n",
        "\n",
        "            # Compute gradients and update weights\n",
        "            gradients = tape.gradient(loss, bert_model_demo.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, bert_model_demo.trainable_variables))\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\"loss\": total_loss.numpy() / (pbar.n + 1)}) #average loss per batch\n",
        "            pbar.update(1)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {total_loss.numpy()}\") #total loss for the epoch\n",
        "        #experiment_with_margins(anchor_output, positive_output, negative_output)\n",
        "\n",
        "    print(\"Training complete.\")"
      ],
      "metadata": {
        "id": "Jt9mqmVBRyZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "sampled_train_df = train_df.sample(n=100, random_state=42)\n",
        "\n",
        "# Select random indices within the range of the sampled dataframe\n",
        "train_indices = random.sample(range(len(sampled_train_df)), min(100, len(sampled_train_df)))\n",
        "training_data = []\n",
        "print(\"sampled_train_df Length:\", len(sampled_train_df))\n",
        "\n",
        "# Preparing training triplets with a hard negative sampling strategy\n",
        "for index in train_indices:\n",
        "    row = sampled_train_df.iloc[index]\n",
        "    pref_label = row['pref_label']\n",
        "    altlabel_es = row['altlabel_es'].split(', ')[0]  # Use the first entry of altlabel as positive\n",
        "    negative_text = get_negatives_diff_lang(neg_df, altlabel_it)\n",
        "\n",
        "    training_data.append((pref_label, altlabel_it, negative_text))\n",
        "\n",
        "print(\"Training Data:\", training_data)  # Check to confirm it's populated\n",
        "print(\"training_data Length:\", len(training_data))\n",
        "\n",
        "# Proceed to train the model with the prepared training data\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR) #Supressing this warning - WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
        "train_model(training_data)"
      ],
      "metadata": {
        "id": "PeE6Bo6DCmU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep an eye on.\n",
        "\n",
        "*   Monitoring: Focus on the average loss per batch and the trend over epochs to ensure your model is learning.\n",
        "\n",
        "*   Expectations: High initial loss values are normal, but the key is a decreasing trend and eventual stabilization."
      ],
      "metadata": {
        "id": "ikoYw_oL-woV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NarX5v9_DW09",
        "outputId": "2d38f95b-4555-401a-8902-907fbb56c9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_model_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  177853440 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 177853440 (678.46 MB)\n",
            "Trainable params: 177853440 (678.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training"
      ],
      "metadata": {
        "id": "uSE5t139r6bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoModelForSeq2SeqLM, NllbTokenizer\n",
        "\n",
        "# Define the directory and model save path\n",
        "directory = '/content/drive/MyDrive/Colab Notebooks/Thesis notebooks/Neural-approach/trained_model/it_nl_de_es_fr_zh_full'#'/content/drive/MyDrive/Colab Notebooks/Thesis notebooks/Neural-approach/demo_trained_model/500_demo'\n",
        "file_name = 'tf_model.h5' #nllb_ft_src_tgt\n",
        "model_save_path = os.path.join(directory, file_name)\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Save the model and tokenizer\n",
        "bert_model_demo.save_pretrained(directory)\n",
        "tokenizer_demo.save_pretrained(directory)\n",
        "\n",
        "loaded_tokenizer = BertTokenizer.from_pretrained(directory)\n",
        "loaded_model = TFAutoModel.from_pretrained(directory)\n",
        "loaded_model.load_weights(model_save_path)\n",
        "\n",
        "print(\"Model and tokenizer saved and loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYIJGO7lWJR7",
        "outputId": "3f7234fc-5e35-415c-994d-a0ef8cafb141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/Thesis notebooks/Neural-approach/trained_model/it_nl_de_es_fr_zh_full.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved and loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Extract embeddings after training\n",
        "source_outputs = loaded_model(source_inputs['input_ids'], attention_mask=source_inputs['attention_mask'])\n",
        "source_embeddings = source_outputs.last_hidden_state[:, 0, :].numpy()\n",
        "target_outputs = loaded_model(target_inputs['input_ids'], attention_mask=target_inputs['attention_mask'])\n",
        "target_embeddings = target_outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "# Combine embeddings for visualization\n",
        "final_embeddings = np.concatenate((source_embeddings, target_embeddings), axis=0)\n",
        "\n",
        "# Visualize final embeddings with Plotly\n",
        "fig2 = visualize_embeddings_plotly(final_embeddings, source_labels, target_labels, 'Final BERT Embeddings')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "4uxambzNdAry",
        "outputId": "324dd855-ce7e-4228-fd27-3d06b37904ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c6226447-2edb-4e92-9b4b-23d69cf3c298\" class=\"plotly-graph-div\" style=\"height:400px; width:1200px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c6226447-2edb-4e92-9b4b-23d69cf3c298\")) {                    Plotly.newPlot(                        \"c6226447-2edb-4e92-9b4b-23d69cf3c298\",                        [{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[69.81476593017578,-0.4062672257423401],\"y\":[-13.883499145507812,4.545027732849121],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":true,\"text\":[\"Hafnium tetrachloride\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[69.81476593017578],\"y\":[-13.883499145507812],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":true,\"text\":[\"Cloruro di afnio(IV)\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[-0.4062672257423401],\"y\":[4.545027732849121],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[-239.5979461669922,-249.37054443359375],\"y\":[-94.35261535644531,-70.84285736083984],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Wittichenite\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[-239.5979461669922],\"y\":[-94.35261535644531],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"Wittichenite\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[-249.37054443359375],\"y\":[-70.84285736083984],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[7.921032428741455,0.8772649765014648],\"y\":[134.21441650390625,109.04973602294922],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Barium chlorate\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[7.921032428741455],\"y\":[134.21441650390625],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"Clorato di bario, clorato di bario bario clorato\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[0.8772649765014648],\"y\":[109.04973602294922],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[-64.39667510986328,29.86001205444336],\"y\":[23.737119674682617,-6.9779839515686035],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Quartz\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[-64.39667510986328],\"y\":[23.737119674682617],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"Biossido di silice, Diossido di silicio, quarzo, silanamina, 1,1,1-trimetil-N-\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[29.86001205444336],\"y\":[-6.9779839515686035],\"type\":\"scatter\"},{\"line\":{\"color\":\"gray\",\"width\":1},\"mode\":\"lines\",\"showlegend\":false,\"x\":[-40.92232131958008,-30.747900009155273],\"y\":[-47.906700134277344,-0.4577588438987732],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"size\":15,\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"Source\",\"showlegend\":false,\"text\":[\"Cyanuric acid\"],\"textfont\":{\"color\":\"blue\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"top right\",\"x\":[-40.92232131958008],\"y\":[-47.906700134277344],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\",\"size\":15,\"symbol\":\"square\"},\"mode\":\"markers+text\",\"name\":\"Target\",\"showlegend\":false,\"text\":[\"acido cianurico\"],\"textfont\":{\"color\":\"red\",\"family\":\"Arial\",\"size\":14},\"textposition\":\"bottom left\",\"x\":[-30.747900009155273],\"y\":[-0.4577588438987732],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"legend\":{\"title\":{\"text\":\"Label Type\"}},\"xaxis\":{\"title\":{\"text\":\"Dimension 1 (t-SNE)\"},\"scaleanchor\":\"y\",\"scaleratio\":1},\"yaxis\":{\"title\":{\"text\":\"Dimension 2 (t-SNE)\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"margin\":{\"l\":40,\"r\":40,\"t\":40,\"b\":40},\"title\":{\"text\":\"Final BERT Embeddings\"},\"width\":1200,\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c6226447-2edb-4e92-9b4b-23d69cf3c298');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_and_download_plot_as_pdf(fig2, '/content/altlabel_it_after.pdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0b0QjT3bPLmo",
        "outputId": "28c336c2-4bc8-40cd-84a4-dbdb776e3445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed860d98-0a22-4162-81ea-476e7ace2110\", \"altlabel_it_after.pdf\", 17715)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}